# main.py
import os
import openai
from fastapi import FastAPI, Request
from fastapi.responses import FileResponse
from pydantic import BaseModel
from typing import Dict
from dotenv import load_dotenv
from fastapi.middleware.cors import CORSMiddleware

from utils.preprocessing import normalize_text
from nlp.intent_detector import IntentDetector
from nlp.sentiment_emotion import EmotionAnalyzer
from nlp.ner_extractor import FinanceEntityExtractor
from rag.search import RAGSearcher
from agent.memory import ConversationMemory
from agent.decision import EscalationDecider

# Carregar vari√°veis de ambiente do arquivo .env
load_dotenv()

# üîß Configura√ß√£o da chave OpenAI
client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ‚öôÔ∏è Inicializa√ß√£o
app = FastAPI()

@app.get("/")
async def read_index():
    """Serve o arquivo de frontend index.html."""
    # Constr√≥i o caminho absoluto para o arquivo index.html
    # partindo do diret√≥rio do main.py e subindo um n√≠vel para a raiz do projeto.
    frontend_path = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'frontend', 'index.html'))
    if os.path.exists(frontend_path):
        return FileResponse(frontend_path)
    return {"error": "index.html not found"}

# CORS Middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Permite todas as origens
    allow_credentials=True,
    allow_methods=["*"],  # Permite todos os m√©todos
    allow_headers=["*"],  # Permite todos os cabe√ßalhos
)

@app.get("/")
async def read_root():
    return FileResponse('../frontend/index.html')

intent_detector = IntentDetector()
emotion_analyzer = EmotionAnalyzer()
ner_extractor = FinanceEntityExtractor()
searcher = RAGSearcher()
memory = ConversationMemory()
decider = EscalationDecider()

# üì• Modelo da requisi√ß√£o
class ChatInput(BaseModel):
    session_id: str
    message: str

@app.post("/chat")
async def chat_handler(input: ChatInput):
    session_id = input.session_id
    user_message = input.message

    # 1. Armazenar mensagem do usu√°rio
    memory.add_message(session_id, "user", user_message)

    # 2. Pr√©-processamento
    clean_text = normalize_text(user_message)

    # 3. NLP: inten√ß√£o, emo√ß√£o, entidades
    intent = intent_detector.predict_intent(clean_text)
    emotion = emotion_analyzer.analyze(clean_text)
    entities = ner_extractor.extract(user_message)

    # 4. Busca sem√¢ntica (RAG)
    docs = searcher.search(clean_text, top_k=3)
    context = "\n\n".join([d["text"] for d in docs])

    # 5. Mem√≥ria + contexto
    history = memory.get_history(session_id)
    history_text = "\n".join([f"{m['role']}: {m['message']}" for m in history[-5:]])

    # 6. Monta prompt para o LLM
    prompt = f"""
    Voc√™ √© um assistente banc√°rio inteligente. Sua tarefa √© responder √†s perguntas do cliente de forma clara, emp√°tica e precisa.

    **Contexto da Conversa:**
    {history_text}

    **Informa√ß√µes Relevantes (Base de Conhecimento):**
    {context}

    **An√°lise da Mensagem do Cliente:**
    - Inten√ß√£o: {intent['intent']} (Confian√ßa: {intent['confidence']})
    - Emo√ß√£o: {emotion['sentiment']} ({emotion['emotions'][0]['label']})
    - Entidades: {entities}

    **Instru√ß√µes:**
    1. Use o hist√≥rico e o contexto para dar uma resposta informada.
    2. Se a inten√ß√£o for "desconhecida" ou a confian√ßa for baixa, pe√ßa ao cliente para reformular a pergunta.
    3. Se a emo√ß√£o for negativa (raiva, nojo), seja especialmente cuidadoso e emp√°tico.
    4. Responda diretamente √† √∫ltima mensagem do cliente: "{user_message}"
    """

    # 7. Gera√ß√£o de Resposta com OpenAI
    try:
        completion = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": prompt},
                {"role": "user", "content": user_message}
            ],
            max_tokens=250,
            temperature=0.7
        )
        response_text = completion.choices[0].message.content

    except Exception as e:
        response_text = "Desculpe, estou com dificuldades para processar sua solicita√ß√£o no momento."
        print(f"Erro ao chamar a API da OpenAI: {e}")

    # 8. Armazenar resposta do assistente
    memory.add_message(session_id, "assistant", response_text)

    # 9. Decis√£o de escalonamento (opcional, pode ser expandido)
    escalate = decider.should_escalate(session_id, emotion, intent['intent'])

    # 10. Formatar e retornar a resposta
    return {
        "session_id": session_id,
        "response": response_text,
        "intent": intent,
        "emotion": emotion,
        "entities": entities,
        "escalate": escalate,
        "rag_context": context
    }
